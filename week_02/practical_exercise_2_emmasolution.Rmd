---
title: "practical_exercise_2, Methods 3, 2021, autumn semester"
author: "Emma Risgaard Olsen"
date: "29th of September 2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

<style type="text/css">
  body{
  font-size: 14pt;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

pacman::p_load(tidyverse, dplyr, magrittr,knitr, patchwork, ggplot2, lme4, stats, grid, ggpubr, ggrepel, graphics, effects)

```

# Assignment 1: Using mixed effects modelling to model hierarchical data
In this assignment we will be investigating the _politeness_ dataset of Winter and Grawunder (2012) and apply basic methods of multilevel modelling. 

## Dataset
The dataset has been shared on GitHub, so make sure that the csv-file is on your current path. Otherwise you can supply the full path.

```{r, include=FALSE}
setwd("/Users/emmaolsen/OneDrive - Aarhus Universitet/Methods3/github_methods_3/week_02")
politeness <- read.csv('politeness.csv') ## read in data
```

# Exercises and objectives
The objectives of the exercises of this assignment are:  
1) Learning to recognize hierarchical structures within datasets and describing them  
2) Creating simple multilevel models and assessing their fitness  
3) Write up a report about the findings of the study  

REMEMBER: In your report, make sure to include code that can reproduce the answers requested in the exercises below  
REMEMBER: This assignment will be part of your final portfolio

## Exercise 1 - describing the dataset and making some initial plots

1) Describe the dataset, such that someone who happened upon this dataset could understand the variables and what they contain  
  i. Also consider whether any of the variables in _politeness_ should be encoded as factors or have the factor encoding removed. Hint: ```?factor```  

The dataset consists of 224 observations of 7 different variables (all listed below). 

```{r, include=FALSE}

ls.str(politeness)
glimpse(politeness)
unique(politeness$scenario)

```

*subject (i.e. the participant)*
*The subject variable represents each participant's individual ID, which makes it easier for us to distinguish between the participants and account for possible individual differences. This variable is a character string containing 16 different subject ID's, each subject ID has 14 rows*

```{r}
# additional information about subject variable
length(unique(politeness$subject)) #amount of different participants
politeness$subject <- as.factor(politeness$subject)
```

*gender (encoded as F for female or M for male)*
*The gender variable represents the gender each participant identifies with.  56.25% of the participants are Female and 43.75% are Male, which is also visually illustrated by a bar plot. The variable is binary as it only contains either F or M, and for analytic purposes it will be transformed into a factor variable.* 

```{r}
n <- nrow(politeness)  # Number of rows in total
(percent_gender <- table(politeness$gender)/n * 100) #generating percentages of gender

politeness$gender <- as.factor(politeness$gender)

#gender variable plot
barplot(percent_gender,ylim=c(0,100), ylab="percent",main="Barplot of Gender")

```

*scenario:* 
*The scenario variable is an integer-variable and indicates which of the 7 different scenarios the participant is in). Each participant completes each trial/scenario twice (either informal or polite), explaining why we have 14 rows per participant.For analytic purposes it will be transformed into a factor variable.* 

```{r}
politeness$scenario <- as.factor(politeness$scenario)
```


*attitude:*
*The attitude variable is a binary variable taking two possible values, i.e "inf" (which corresponds to "informal") and "pol" (which corresponds to "formal").The participants were asked to do each scenario in a formal and informal way. For analytic purposes it will be transformed into a factor variable.* 

```{r}
politeness$attitude <- as.factor(politeness$attitude)
```


*total_duration (i.e. the duration of a given scenario)*
The total duration variable is a numeric variable representing duration of each response (for how much time the participants were talking). The distribution of the variable is positively skewed (right-skewed distribution).The minimum value in the variable is 0.988 and the maximum value in the variable is 101.375, in addition to this the mean of the variable is 24.176.
```{r}
#total duration variable plot
ggplot(politeness, aes(total_duration))+geom_density()

summary(politeness$total_duration) # summary statistics
```


*f0mn. (i.e. the base frequency, pitch):*
*The variable f0mn represents the frequency (i.e., pitch) of the voice in hertz. This variable is numeric and the distribution of the data is bimodal. The minimum value in the variable is 80.8 hz and the maximum value in the variable is 415.8 hz, in addition to this the mean of the variable is 197.9 hz. The f0mn variable contains some NA's, and for analytic purposes, I replace these missing values with imputed values based on other characteristics of the record (in this context it will be replaced with a mean of f0mn for each subject).* 

```{r}
# f0mn variable plot
ggplot(politeness, aes(f0mn))+geom_density()

# replacing NA's with mean per participant
politeness <- politeness %>% 
  group_by(subject) %>% 
  mutate(f0mn = ifelse(is.na(f0mn), mean(f0mn, na.rm = TRUE), f0mn))

```


*hiss_count. (i.e. the number of hisses made)* 
*The hiss count variable relates to the amount of loud "hissing" breath intake. This variable is an integer variable with a minimum value of 0 and a maximum hissing value of 5. The distribution of the data is positively skewed (right-skewed distribution).* 

```{r}
#hiss count variable plot
ggplot(politeness, aes(hiss_count))+geom_density()
```



2) Create a new data frame that just contains the subject _F1_ and run two linear models; one that expresses _f0mn_ as dependent on _scenario_ as an integer; and one that expresses _f0mn_ as dependent on _scenario_ encoded as a factor  

```{r}
F1 <- politeness[(politeness$subject=="F1"),] # create df just for subject F1

```

```{r}
# Linear model with scenario encoded as integer
class(F1$scenario) # class = "integer"
lm1 <-lm(f0mn~scenario, data=F1) 

# Linear model with scenario encoded as factor
lm2 <- lm(f0mn ~ as.factor(F1$scenario), data=F1) 

lm1;lm2

```


  i. Include the model matrices, $X$ from the General Linear Model, for these two models in your report and describe the different interpretations of _scenario_ that these entail
    ii.  coding of _scenario_, as a factor or not, is more fitting?

```{r}

# Model matrices
X_matrix_integer <- model.matrix(lm1) # model matrix with scenario as integer
X_matrix_factor <- model.matrix(lm2) # model matrix with scenario as factor

X_matrix_integer;X_matrix_factor
```
The design matrix for the model with scenario as an integer take scenario as a continuous variable where going from 2 to 4 is some meaningful doubling. We therefore not only take the scenarios as having some kind of meaningful order, but also take scenario 6 is being double the amount of scenario 3, all in all treating it as a continuous variable (which is of course wrong, since we have no expectation that f0mn will change systematically with increasing scenario number).

The design matrix for the model with scenario as a factor take scenario to be a categorical variable. In the design matrix we can see all the different observations of scenario coded as dummy variables, so every factor level has its own beta-value connected to it. Scenario 1 is "excluded" since that will be the intercept.
    
*The model lm1 expresses pitch as dependent on scenario as an integer. The design matrix for this model does not treat each scenario separately, but considers scenario as a numeric, continuous variable. In this case, we model just one intercept and one slope. This implies interpreting the model slope which is -6.886 as follows: per increment of scenariom the pitch will go down by 6.886 hz. This is a faulty interpretation, as the 2x2 matrix shows that we would then interpret scenario 7, as being 7 times more than scenario 1, 4 twice as much as 2 etc - which we for sure know is not the case.*

*Model 2 (lm2) expresses pitch as dependent on scenario encoded as a factor, which is more fitting. When the "scenario" variable is factor, it is treated categorically by R, meaning that we are modeling one intercept and 6 different slope, one for each scenario. This enables us to interpret the output of the model 2 correctly as follows; going from scenario 1 to scenario 2 the pitch increases by 62.40 hz, going from scenario 1 to scenario 3 the pitch increases by 35.35 hz etc. The model matrix of model 2 shows multiple columns (one for each scenario), meaning that we can look at each scenario individually, and thereby investigate their meaning properly.*

*Thus, coding the "scenario" variable as a factor provides the most accurate information, and eliminates any hierarchical relations in the variable.*

    
3) Make a plot that includes a subplot for each subject that has _scenario_ on the x-axis and _f0mn_ on the y-axis and where points are colour coded according to _attitude_
    i. Describe the differences between subjects
    
```{r}

pacman::p_load(tidyverse, grid, ggpubr, ggrepel)

politeness %>% 
  ggplot(aes( x = scenario, y = f0mn, colour = attitude)) +
  geom_point() +
  facet_wrap(~subject)

```

The main difference between each subject is the pitch of voice in hertz. The subplots show a tendency of male subjects having a lower pitch of voice, and the female subjects tend to have higher pitch of voice. Likewise, the subplots demonstrate how there are individual differences within pitch of voice, reminding us that we must account for this by including subjects as a random effect when modeling the data. For most subjects the attitudes don't differ uch across scenarios. There are, however, exceptions (F5, F9, M4). It also seems that the attitude for informal generally has a slightly higher pitch than that of polite. 

  
## Exercise 2  - comparison of models

1) Build four models and do some comparisons
    i. a single level model that models _f0mn_ as dependent on _gender
    ii. a two-level model that adds a second level on top of i. where unique intercepts are modelled for each _scenario_
    iii. a two-level model that only has _subject_ as an intercept' 
    iv. a two-level model that models intercepts for both _scenario_ and _subject_
    
```{r 2.1i}
# i) a single level model that models f0mn as dependent on _gender
m1 <- lm(f0mn~gender, data=politeness)
```
    
```{r 2.1ii}
# ii) a two-level model with scenario as random intercept
m2 <- lmer(f0mn~gender + (1|scenario), data=politeness)
# ranef(m2) # extract random effects
```

```{r 2.1iii}
# iii) a a two-level model that only has subject as a random intercept
m3 <- lmer(f0mn~gender+(1|subject),data=politeness, REML = F)
# ranef(m3) # extract random effects
```

```{r}
# iv) a two-level model that models intercepts for both scenario and subject
m4 <- lmer(f0mn~gender+(1|scenario)+(1|subject),data=politeness)
#ranef(m4) # extract random effects

```

  v.  which of the models has the lowest residual standard deviation, also compare the Akaike Information Criterion `AIC`?

```{r}

AIC <- c(AIC(m1),AIC(m2),AIC(m3),AIC(m4))
sigma <- c(sigma(m1),sigma(m2),sigma(m3),sigma(m4)) # Residual standard deviation

tibble("Model"=c("m1","m2","m3","m4"), AIC, sigma)

```

We see that the model with the lowest residual standard deviation is m4 (i.e. the two-level model that models intercepts for both scenario and subject). This model has a residual standard deviation of 29.9 and does also has the lowest AIC value (of 2198.778). 
  
  vi.  which of the second-level effects explains the most variance?
```{r}

# comparing conditional R2 within the second levels
MuMIn::r.squaredGLMM(m2) #R2c = 0.698216
MuMIn::r.squaredGLMM(m3) #R2c = 0.8002449
MuMIn::r.squaredGLMM(m4) #R2c = 0.816289

```

The AIC and residual standard deviation is lower for the model with only the _subject_ as random intercept compared to the one with _scenario_. This signifies that model from iii explains the most variance. Also, when comparing only the second-levels effects (model 2 and model 3) by their Conditional R2 (R2c) which states how much variance is explained by both random and fixed effects, it is shown that model 2 has an R2c of 0.698216 and model 3 has an R2c of 0.8002449, and thus stating that the second-level effect "subject" explains the most variance. 


2) Why is our single-level model bad?

  i. create a new data frame that has three variables, _subject_, _gender_ and _f0mn_, where _f0mn_ is the average of all responses of each subject, i.e. averaging across _attitude_ and_scenario_
  
```{r}
library(dplyr)

newdf <- politeness[c(1,2,6)] # create df as a subset of politeness df
newdf <- newdf %>% 
  group_by(subject) %>% 
  mutate(Mean = mean(f0mn)) %>% 
  ungroup()

newdf$f0mn <- NULL
newdf <- rename(newdf, f0mn = Mean) # rename the old variable "Mean" and call it "f0mn" instead

# head(newdf)
```
  
  ii. build a single-level model that models _f0mn_ as dependent on _gender_ using this new dataset

```{r}
newmodel <- lm(f0mn ~ gender, data=newdf)
```

iii. make Quantile-Quantile plots, comparing theoretical quantiles to the sample quantiles) using `qqnorm` and `qqline` for the new single-level model and compare it to the old single-level model (from 1). Which model's residuals ($\epsilon$) fulfil the assumptions of the General Linear Model better?)

*QQ-PLOT OF SINGLE LEVEL MODEL:*
```{r}
# Same way but more simple code
qqnorm(resid(newmodel),pch = 1, frame = FALSE)
qqline(resid(newmodel),col = "steelblue", lwd = 2)
```

In the above qq-plot, it seems as if the errors are rather systematic - indicating that a linear fit of the data might not be appropriate. 


*QQ-PLOT OF MODEL1 (I.E. THE OLD SINGLE-LEVEL MODEL:*
```{r}
# Same way but more simple code to do a qq-plot of old single level model
qqnorm(resid(m1),pch = 1, frame = FALSE)
qqline(resid(m1),col = "steelblue", lwd = 2)
```

iv) Also make a quantile-quantile plot for the residuals of the  multilevel model with two intercepts. Does it look alright?
```{r}
qqnorm(resid(m4))
qqline(resid(m4),col="orange")
```

From looking at the QQ plots, the old model seems to fulfill the assumptions of the GLM better. However, both the new single-level model and the old single-level model seem to violate the assumption of normally distributed residuals as the both QQ-plots indicates a skewed distributions. Averaging the outcome variable across scenarious discards a lot of potentially usefull information, so in practice, it is not a very informative model.

However, violation of the assumption of normality of residuals is not the most important violation that makes our single level model bad. Our single level model is bad because the repeated measures design violates the assumption of independence that the linear model has. Using a single-level model, the data used to make the model violates the very assumptions upon which our model is build, and thus the model is not very informative. We simply can't use a single-level model to model data from a repeated measures design (which is the case here) - for that, we need to make a multilevel model, taking both random and fixed effects into account. 

The QQ-plot for the residuals of the  multilevel model with two intercept looks alright, although the residual distribution seems to be heavy tailed. The QQ-plot for the residuals of model 4 looks a little better than model 1 and the single-level model, but still has a right skewed tail. This violation of normality of residuals can be accepted since linear models are relatively robust against violations of the assumptions of normality. This model does not violate the assumption of independence, which is more important. 



3) Plotting the two-intercepts model
    i. Create a plot for each subject, (similar to part 3 in Exercise 1), this time also indicating the fitted value for each of the subjects for each for the scenarios (hint use `fixef` to get the "grand effects" for each gender and `ranef` to get the subject- and scenario-specific effects)

```{r}
fitted <- fitted(m4)

politeness$fitted_f0mn <- fitted

ggplot(politeness, (aes(x = scenario, y = f0mn, color = attitude)))+ 
  geom_point()+
  geom_point(aes(scenario, fitted_f0mn), color = "darkblue", size=0.6)+
  facet_wrap(.~subject)+ 
  theme_bw()

```

In the plot above, the black dots indicate the fitted value for each of the subjects for each of the scenarios. The colored dots indicate the observed values. 

    
## Exercise 3 - now with attitude

1) Carry on with the model with the two unique intercepts fitted (_scenario_ and _subject_).
  i. now build a model that has _attitude_ as a main effect besides _gender_

```{r}
m5 <- lmer(f0mn~gender+attitude+(1|subject)+(1|scenario),data=politeness)

```
  
  ii. make a separate model that besides the main effects of _attitude_ and _gender_ also include their interaction

```{r}

m6 <- lmer(f0mn~gender*attitude+(1|subject)+(1|scenario),data=politeness, REML=F)
```

   iii. describe what the interaction term in the model says about Korean men's pitch when they are polite relative to Korean women's pitch when they are polite (you don't have to judge whether it is interesting)  
   
First of all, it is important to state that the interation term was not found to be statistically significant at the 5% significance level (as p-value > 0.05), and thus doesn't justify the inclusion of the term in our model. Moreover, the plot below indicates overlapping error bars, also indicating the absence of a real interaction effect.

```{r}
plot(allEffects(m6), multiline=TRUE, ci.style="bars")
```

Nonetheless, the following section will describe the interpretation of the interaction effect, assuming that it was statistically significant. 

Our interaction term "genderM:attitudepol" is 5.544. The coefficient on the interaction term represents the difference in the slope for f0mn comparing female and males as well as polite/informal. In other words, it indicates how the effect of attitude being polite changes when gender goes from female (our reference) to male. This tells us that for Males, the pitch in decreases with LESS than for Females i.e 5,781 hz less in the polite condition. In other words, women's frequency is more influenced by going from informal to polite attitudde than males' pitch is. 

Thus, Korean men's pitch when they are polite are higher than Korean women's pitch when they are polite, in relation to them selves (as we have modelled indvidual intercepts for each subject). So the change in pitch is lower for Males than for Females in the polite condition.
  
"Attitudepol" indicates that the pitch generally decreases with -15.646 hz when going from informal to polite

The estimate for "intercept" is the estimate for the Female category, and the estimate for the difference between the females and the male category. The p-value in each row is simply a test of whether the coefficient to the left is significantly different from zero. 
  
2) Compare the three models (1. gender as a main effect; 2. gender and attitude as main effects; 3. gender and attitude as main effects and the interaction between them. For all three models model unique intercepts for _subject_ and _scenario_) using residual variance, residual standard deviation and AIC.  

```{r}

# 1. gender as a main effect model 
m4 <- lmer(f0mn~gender+(1|subject)+(1|scenario),data=politeness)

# 2. gender and attitude as main effects. m5 
m5 <- lmer(f0mn~gender+attitude+(1|subject)+(1|scenario),data=politeness)

# 3. gender and attitude as main effects and the interaction between them. 
m6 <- lmer(f0mn~gender+attitude+gender*attitude+(1|subject)+(1|scenario),data=politeness)


#comparing conditional R2 within the second levels
MuMIn::r.squaredGLMM(m4) #R2c = 0.816289
MuMIn::r.squaredGLMM(m4)  #R2c = 0.8253963
MuMIn::r.squaredGLMM(m6) #R2c = 0.8251343


modeltxt <- c('m4', 'm5', 'm6')
sigmas <- c(sigma(m4), sigma(m5), sigma(m6)) # Residual standard deviation
varres <- c(var(resid(m4)), var(resid(m5)), var(resid(m6))) # Residual variance
as_tibble(cbind(modeltxt, AIC(m4, m5, m6), sigmas, varres))

```

When comparing the three new models (1. gender as a main effect; 2. gender and attitude as main effects; 3. gender and attitude as main effects and the interaction between them. All of them having unique intercepts for _subject_ and _scenario_), the residual variance, residual standard deviation and AIC, looks as followed: 
  Model 4 has a sigma = 29.9, an AIC = 2198.778, and residual variance = 819. 
  Model 5 has a sigma = 29.1, an AIC = 2185.125, and residual variance = 775. 
  Model 6 has a sigma = 29.2, an AIC = 2180.623, and residual variance = 773.

Model 4 (the model with gender as a main effect) has both the highest residual standard deviation, AIC value and residual variance and is thus the worst performing model out of the 3 models.

Model 5 has the lowest sigma and Model 6 has the lowest AIC, but they all don't vary much in their sigma, AIC and R2c.


3)  Choose the model that you think describe the data the best - and write a short report on the main findings based on this model. At least include the following:

*Based on the previous analysis of the data and modeling, the best model would be model 6:

```{r}
f0mn ~ gender + attitude + (1|subject) + (1|scenario)
```

Additionally, it was found that attitude significantly predicts frequency (β = -14.82, p< .001). This means that males generally have a lower frequency compared to women, and that changing attitude from informal to polite tends to result in a lower frequency when the other variables are held constant. 

We see that there is a higher variance (585.6) and std. dev. (24.20) for the second level effect subject compared to the second level effect of scenario where variance (106.7) and std. dev. (10.33) which means that there is a higher variability within _subjects_ compared to _scenarios_. 

The special thing shown by our model is that both Korean men and women's frequency gets lower in polite scenarios compared to informal scenarios, whereas in many other languages it is the opposite, when in polite scenarios the pitch gets higher for both men and women (Winter, 2013) ergo there are also cultural differences. 


  i. describe what the dataset consists of  

*The variables used in the model are; f0mn, gender, attitude, subject, and scenario.*
*"f0mn" is our dependent variable, representing voice pitch in hertz.*

*It is important to do multilevel modelling on the data in order to account for the repeated measures design of the experiment.Our fixed effects are gender and attitude. Our random effects are subject and scenario, both of which has been modelled as random intercepts in the model. We chose not to include the interaction between gender and attitude as it was found to be statistically insignificant and therefore, it would not be possible to justify including it in the model without further theoretical support.*

*It is necessary to include random intercepts for each subject as we would expect naturally occurring baseline differences between different subject, which needs to be taking into acount in order to model pitch change under certain conditions.* 

*"gender" is one of our independent variables and represents which gender each subject identifies as (Female or Male). We would expect systematic differences based on subjects' genders.*

*"attitude" represents two types of conditions for each trial (Informal or Polite)* 
*"subject" represents each subject's individual participant ID*
*"scenario" represents 7 different trials, each with 2 different conditions, hence 14 rows per subject.*

  ii. what can you conclude about the effect of gender and attitude on pitch (if anything)?  

```{r}
summary(m6)
```

*The summary output of model 6 allows us to investigate the coefficient. The intercept was 254.193, which is equivalent to the average frequency of women in the informal condition.*

*Going from female (with an intercept of 254.193 hz) to male, the pitch of voice decreases by 117.983 hz. When the attitude goes from "informal" to "polite", the pitch of voice decreases by 15.646 hz. when all other variables are held constant*
      *- Females in informal attitude condition has an average pitch of 254.193 (intercept)*
      *- Females in polite attitude condition has a pitch of 238.547 i.e. (254.193-15.646)*. 
      *- Males in informal attitude condition has a pitch of 136.21 hz i.e. (254.193-117.983)*
      *- Males in polite attitude condition has a pitch of 120.564 hz i.e. (254.193-(-117.983-15.646))* 

*According to the interaction effect, males pitch decreases with LESS than for Females i.e 5,781 hz less in the* *polite condition. Thus, Korean men's pitch when they are polite are higher than Korean women's pitch when they* *are polite, in relation to them selves (as we have modelled indvidual intercepts for each subject). So the* *change in pitch is lower for Males than for Females in the polite condition.*

*The output also tells us that there is a higher variance (610.37) and std. dev. (24.71) for the second level effect subject as compared to the second level effect of scenario (83.17) and std. dev. (9.12). This indicates that there is a higher variability within subjects as compared to scenarios.* 

*Another thing that can be derived about pitch from our model is related specifically to the Korean language and the cultural differences associated with different languages. Our model indicates that regardless of gender, the subjects' frequency is higher in informal scenarious as compared to polite scenarios, which is opposite of the case of many other languages where "many researchers have found or suggested that there is an association between high pitch and polite speech" (Winter, 2013).*

*It has been claimed that in Korean, female speakers lower their pitch when speaking to superiors (Shin 2005), which is supported by our data (although the interaction effect is insignificant)*.
  
  iii. motivate why you would include separate intercepts for subjects and scenarios (if you think they should be included)  

*It makes sense to include separate intercepts for the variables "subject" and "scenario", since we then assume* *that each subject and scenario has different baselines - a different average effect in pitch per subject and* *scenario. By making separate intercepts, we account for individual differences across subject and scenario.* 

  iv. describe the variance components of the second level (if any)  
*This model has a sigma = 29.16333, an AIC = 2180.623, and a R2c = 0.8251343. The model has a slightly better AIC value than the other models, but a slightly worse sigma and R2c than model 5. *  
  
  v. include a Quantile-Quantile plot of your chosen model 
*When comparing a Q-Q-plot from model 6 and Q-Q-plot from model 5, the values seem to fit the line slightly better for model 6, but it is still has a right skewed tail. The residuals of the chosen model (m5) indicated minor violations from normality primarily at the right end of the line. Conceptually, model 6 might be justifiable, as one could argue that pitch would get affected depending on both gender and attitude (the interaction). However, as mentioned, the interaction was found to be insignificant and further theory would be needed to support this.* 

I have chosen model m5.

```{r}

qqnorm(residuals(m6))
qqline(residuals(m6))

# for comparison 
qqnorm(resid(m5))
qqline(resid(m5))

qqnorm(resid(m4))
qqline(resid(m4))

```

